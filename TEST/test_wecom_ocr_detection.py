#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨OCRæ£€æµ‹ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£æ¶ˆæ¯åŒºåŸŸçš„å˜åŒ–
ç”¨äºåˆ¤æ–­AIå›å¤å®Œæˆçš„æ—¶æœº
"""

import time
import win32gui
import win32process
import win32ui
import win32con
from PIL import Image
import pytesseract
import os
import hashlib
from wxauto.utils.win32 import GetAllWindows

class WeChatOCRDetector:
    def __init__(self):
        self.last_text_hash = None
        self.last_full_text = ""
        self.stable_count = 0
        self.required_stable_checks = 6  # éœ€è¦è¿ç»­6æ¬¡(3ç§’)ç¨³å®šæ‰è®¤ä¸ºå®Œæˆ
        
        # è®¾ç½®tesseractè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
        
    def find_wecom_chat_windows(self):
        """æŸ¥æ‰¾ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£"""
        chat_windows = []
        all_windows = GetAllWindows()
        
        for hwnd, class_name, window_title in all_windows:
            if self.is_wecom_chat_window(hwnd, class_name, window_title):
                chat_windows.append((hwnd, window_title))
        
        return chat_windows
    
    def is_wecom_chat_window(self, hwnd, class_name, window_title):
        """åˆ¤æ–­æ˜¯å¦æ˜¯ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£"""
        try:
            if not win32gui.IsWindowVisible(hwnd):
                return False
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¼ä¸šå¾®ä¿¡è¿›ç¨‹
            _, pid = win32process.GetWindowThreadProcessId(hwnd)
            process_name = self.get_process_name(pid)
            
            if "WXWork" not in process_name and "ä¼ä¸šå¾®ä¿¡" not in process_name:
                return False
            
            # æ£€æŸ¥çª—å£ç±»åå’Œæ ‡é¢˜
            if class_name == "WwStandaloneConversationWnd":
                return True
            
            # æ£€æŸ¥ä¸»çª—å£ä¸­çš„å¯¹è¯
            if "ä¼ä¸šå¾®ä¿¡" in window_title and len(window_title) > 3:
                return True
                
            return False
            
        except Exception as e:
            print(f"æ£€æŸ¥çª—å£æ—¶å‡ºé”™: {e}")
            return False
    
    def get_process_name(self, pid):
        """è·å–è¿›ç¨‹åç§°"""
        try:
            import psutil
            process = psutil.Process(pid)
            return process.name()
        except:
            return ""
    
    def capture_window_region(self, hwnd, region_ratio=(0.1, 0.3, 0.9, 0.8)):
        """
        æˆªå–çª—å£çš„æŒ‡å®šåŒºåŸŸ
        region_ratio: (left_ratio, top_ratio, right_ratio, bottom_ratio)
        é»˜è®¤æˆªå–çª—å£ä¸­é—´çš„æ¶ˆæ¯åŒºåŸŸï¼Œé¿å¼€æ ‡é¢˜æ å’Œè¾“å…¥æ¡†
        """
        try:
            # è·å–çª—å£çŸ©å½¢
            rect = win32gui.GetWindowRect(hwnd)
            width = rect[2] - rect[0]
            height = rect[3] - rect[1]
            
            # è®¡ç®—æ¶ˆæ¯åŒºåŸŸçš„å®é™…åæ ‡
            left = int(width * region_ratio[0])
            top = int(height * region_ratio[1])
            right = int(width * region_ratio[2])
            bottom = int(height * region_ratio[3])
            
            crop_width = right - left
            crop_height = bottom - top
            
            # è·å–çª—å£DC
            hwndDC = win32gui.GetWindowDC(hwnd)
            mfcDC = win32gui.CreateCompatibleDC(hwndDC)
            saveBitMap = win32gui.CreateCompatibleBitmap(hwndDC, crop_width, crop_height)
            win32gui.SelectObject(mfcDC, saveBitMap)
            
            # å¤åˆ¶çª—å£æŒ‡å®šåŒºåŸŸåˆ°å†…å­˜DC
            result = win32gui.BitBlt(mfcDC, 0, 0, crop_width, crop_height, 
                                   hwndDC, left, top, win32con.SRCCOPY)
            
            if result:
                # è·å–ä½å›¾ä¿¡æ¯
                bmpinfo = win32gui.GetObject(saveBitMap)
                bmpstr = win32gui.GetBitmapBits(saveBitMap, bmpinfo.bmWidthBytes * bmpinfo.bmHeight)
                
                # è½¬æ¢ä¸ºPILå›¾åƒ
                img = Image.frombuffer(
                    'RGB',
                    (bmpinfo.bmWidth, bmpinfo.bmHeight),
                    bmpstr, 'raw', 'BGRX', 0, 1
                )
                
                # æ¸…ç†èµ„æº
                win32gui.DeleteObject(saveBitMap)
                win32gui.DeleteDC(mfcDC)
                win32gui.ReleaseDC(hwnd, hwndDC)
                
                return img
            else:
                print("æˆªå›¾å¤±è´¥")
                # æ¸…ç†èµ„æº
                win32gui.DeleteObject(saveBitMap)
                win32gui.DeleteDC(mfcDC)
                win32gui.ReleaseDC(hwnd, hwndDC)
                return None
                
        except Exception as e:
            print(f"æˆªå–çª—å£åŒºåŸŸå¤±è´¥: {e}")
            return None
    
    def extract_text_from_image(self, image):
        """ä»å›¾åƒä¸­æå–æ–‡æœ¬"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾åƒä»¥æé«˜OCRå‡†ç¡®æ€§
            gray_image = image.convert('L')
            
            # ä½¿ç”¨pytesseractè¿›è¡ŒOCR
            # é…ç½®OCRå‚æ•°ï¼Œé€‚åˆä¸­æ–‡è¯†åˆ«
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZï¼Œã€‚ï¼Ÿï¼ï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€Â·'
            
            # å°è¯•ä¸­æ–‡+è‹±æ–‡è¯†åˆ«
            try:
                text = pytesseract.image_to_string(gray_image, lang='chi_sim+eng', config=custom_config)
            except:
                # å¦‚æœä¸­æ–‡è¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡è¯†åˆ«
                text = pytesseract.image_to_string(gray_image, lang='eng')
            
            # æ¸…ç†æ–‡æœ¬
            text = text.strip()
            text = '\n'.join(line.strip() for line in text.split('\n') if line.strip())
            
            return text
            
        except Exception as e:
            print(f"OCRè¯†åˆ«å¤±è´¥: {e}")
            return ""
    
    def is_text_stable(self, current_text):
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ç¨³å®šï¼ˆAIå›å¤å®Œæˆï¼‰"""
        # è®¡ç®—æ–‡æœ¬å“ˆå¸Œ
        current_hash = hashlib.md5(current_text.encode('utf-8')).hexdigest()
        
        if current_hash == self.last_text_hash:
            self.stable_count += 1
        else:
            self.stable_count = 0
            self.last_text_hash = current_hash
            self.last_full_text = current_text
        
        # å¦‚æœè¿ç»­å¤šæ¬¡æ£€æŸ¥æ–‡æœ¬éƒ½æ²¡æœ‰å˜åŒ–ï¼Œè®¤ä¸ºAIå›å¤å®Œæˆ
        return self.stable_count >= self.required_stable_checks
    
    def monitor_ai_reply(self, hwnd, window_title):
        """ç›‘æ§AIå›å¤å®ŒæˆçŠ¶æ€"""
        print(f"\nå¼€å§‹ç›‘æ§AIå›å¤: {window_title}")
        print(f"çª—å£å¥æŸ„: {hwnd}")
        print("=" * 60)
        
        # æµ‹è¯•æˆªå›¾å’ŒOCR
        print("æ­£åœ¨æµ‹è¯•æˆªå›¾å’ŒOCRåŠŸèƒ½...")
        test_image = self.capture_window_region(hwnd)
        if test_image:
            print("æˆªå›¾æˆåŠŸ")
            # ä¿å­˜æµ‹è¯•å›¾ç‰‡
            test_image.save("test_screenshot.png")
            print("æµ‹è¯•æˆªå›¾å·²ä¿å­˜ä¸º: test_screenshot.png")
            
            # æµ‹è¯•OCR
            test_text = self.extract_text_from_image(test_image)
            print(f"OCRæµ‹è¯•ç»“æœ: {test_text[:100]}..." if len(test_text) > 100 else f"OCRæµ‹è¯•ç»“æœ: {test_text}")
        else:
            print("æˆªå›¾å¤±è´¥ï¼Œè¯·æ£€æŸ¥çª—å£çŠ¶æ€")
            return
        
        print("\nè¯·åœ¨ä¼ä¸šå¾®ä¿¡ä¸­å‘é€æ¶ˆæ¯ç»™AIï¼Œç„¶åè§‚å¯Ÿæ£€æµ‹ç»“æœ...")
        input("å‡†å¤‡å¥½åæŒ‰å›è½¦å¼€å§‹ç›‘æ§...")
        
        print("\nå¼€å§‹å®æ—¶ç›‘æ§...")
        print("-" * 60)
        
        start_time = time.time()
        check_count = 0
        last_displayed_text = ""
        
        while True:
            check_count += 1
            current_time = time.time()
            elapsed = current_time - start_time
            
            # æˆªå–çª—å£å›¾åƒ
            image = self.capture_window_region(hwnd)
            if not image:
                print(f"ç¬¬{check_count}æ¬¡æ£€æŸ¥å¤±è´¥ï¼šæ— æ³•æˆªå›¾")
                time.sleep(0.5)
                continue
            
            # OCRè¯†åˆ«æ–‡æœ¬
            current_text = self.extract_text_from_image(image)
            
            # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰å˜åŒ–
            text_changed = current_text != last_displayed_text
            
            if text_changed:
                print(f"\næ—¶é—´: {elapsed:.1f}s | æ£€æŸ¥: #{check_count}")
                print("æ£€æµ‹åˆ°æ–‡æœ¬å˜åŒ–:")
                print("-" * 40)
                print(current_text)
                print("-" * 40)
                last_displayed_text = current_text
                
                # ä¿å­˜å˜åŒ–æ—¶çš„æˆªå›¾
                image.save(f"change_{check_count}.png")
                print(f"æˆªå›¾å·²ä¿å­˜: change_{check_count}.png")
            else:
                # ç®€å•æ˜¾ç¤ºçŠ¶æ€
                if check_count % 10 == 0:  # æ¯10æ¬¡æ£€æŸ¥æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
                    print(f"æ—¶é—´: {elapsed:.1f}s | æ£€æŸ¥: #{check_count} | ç¨³å®šæ¬¡æ•°: {self.stable_count}")
            
            # æ£€æŸ¥æ˜¯å¦ç¨³å®š
            is_stable = self.is_text_stable(current_text)
            
            if is_stable and len(current_text.strip()) > 0:
                print(f"\nğŸ‰ æ£€æµ‹åˆ°AIå›å¤å®Œæˆï¼")
                print(f"ç¨³å®šæ—¶é—´: {elapsed:.1f}s")
                print(f"ç¨³å®šæ£€æŸ¥æ¬¡æ•°: {self.stable_count}")
                print("=" * 50)
                print("æœ€ç»ˆå›å¤å†…å®¹:")
                print(self.last_full_text)
                print("=" * 50)
                
                # ä¿å­˜æœ€ç»ˆæˆªå›¾
                image.save("final_reply.png")
                print("æœ€ç»ˆæˆªå›¾å·²ä¿å­˜: final_reply.png")
                break
            
            # é˜²æ­¢æ— é™å¾ªç¯ï¼Œæœ€å¤šç›‘æ§5åˆ†é’Ÿ
            if elapsed > 300:
                print(f"\nç›‘æ§è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œåœæ­¢æ£€æµ‹")
                break
            
            time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
        
        return self.last_full_text
    
    def test_screenshot_and_ocr(self, hwnd, window_title):
        """æµ‹è¯•æˆªå›¾å’ŒOCRåŠŸèƒ½"""
        print(f"\næµ‹è¯•æˆªå›¾å’ŒOCRåŠŸèƒ½: {window_title}")
        print("=" * 50)
        
        # æˆªå–ä¸åŒåŒºåŸŸè¿›è¡Œæµ‹è¯•
        regions = {
            "å…¨çª—å£": (0, 0, 1, 1),
            "ä¸ŠåŠéƒ¨åˆ†": (0, 0, 1, 0.5),
            "ä¸‹åŠéƒ¨åˆ†": (0, 0.5, 1, 1),
            "ä¸­é—´æ¶ˆæ¯åŒº": (0.1, 0.2, 0.9, 0.8),
            "åº•éƒ¨åŒºåŸŸ": (0.1, 0.7, 0.9, 0.95)
        }
        
        for region_name, region_ratio in regions.items():
            print(f"\næµ‹è¯•åŒºåŸŸ: {region_name}")
            image = self.capture_window_region(hwnd, region_ratio)
            
            if image:
                filename = f"test_{region_name}.png"
                image.save(filename)
                print(f"æˆªå›¾ä¿å­˜: {filename}")
                
                # OCRè¯†åˆ«
                text = self.extract_text_from_image(image)
                print(f"OCRç»“æœ: {text[:100]}..." if len(text) > 100 else f"OCRç»“æœ: {text}")
            else:
                print(f"æˆªå›¾å¤±è´¥")
            
            print("-" * 30)

def main():
    print("ä¼ä¸šå¾®ä¿¡OCRæ¶ˆæ¯æ£€æµ‹æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥tesseractæ˜¯å¦å¯ç”¨
    try:
        pytesseract.get_tesseract_version()
        print("âœ“ Tesseract OCR å¯ç”¨")
    except Exception as e:
        print("âœ— Tesseract OCR ä¸å¯ç”¨")
        print("è¯·å®‰è£… Tesseract OCR: https://github.com/tesseract-ocr/tesseract")
        print("æˆ–è€…è®¾ç½®æ­£ç¡®çš„ tesseract_cmd è·¯å¾„")
        print(f"é”™è¯¯: {e}")
        return
    
    detector = WeChatOCRDetector()
    
    # æŸ¥æ‰¾ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£
    print("\næ­£åœ¨æŸ¥æ‰¾ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£...")
    chat_windows = detector.find_wecom_chat_windows()
    
    if not chat_windows:
        print("æœªæ‰¾åˆ°ä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£")
        return
    
    print(f"æ‰¾åˆ° {len(chat_windows)} ä¸ªä¼ä¸šå¾®ä¿¡èŠå¤©çª—å£:")
    for i, (hwnd, title) in enumerate(chat_windows):
        print(f"  {i+1}. {title} (å¥æŸ„: {hwnd})")
    
    if len(chat_windows) == 1:
        selected_window = chat_windows[0]
        print(f"\nè‡ªåŠ¨é€‰æ‹©çª—å£: {selected_window[1]}")
    else:
        try:
            choice = int(input(f"\nè¯·é€‰æ‹©è¦ç›‘æ§çš„çª—å£ (1-{len(chat_windows)}): ")) - 1
            if 0 <= choice < len(chat_windows):
                selected_window = chat_windows[choice]
            else:
                print("é€‰æ‹©æ— æ•ˆï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªçª—å£")
                selected_window = chat_windows[0]
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªçª—å£")
            selected_window = chat_windows[0]
    
    hwnd, window_title = selected_window
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    print(f"\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æµ‹è¯•æˆªå›¾å’ŒOCRåŠŸèƒ½")
    print("2. ç›‘æ§AIå›å¤å®Œæˆ")
    
    try:
        mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1-2ï¼Œé»˜è®¤2): ").strip() or "2"
    except:
        mode = "2"
    
    if mode == "1":
        detector.test_screenshot_and_ocr(hwnd, window_title)
    else:
        final_text = detector.monitor_ai_reply(hwnd, window_title)
        if final_text:
            print(f"\næœ€ç»ˆè·å–åˆ°çš„å®Œæ•´å›å¤:")
            print(f"'{final_text}'")

if __name__ == "__main__":
    main()